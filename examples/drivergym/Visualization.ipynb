{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from l5kit.cle.composite_metrics import CompositeMetricAggregator\n",
    "from l5kit.cle.scene_type_agg import compute_cle_scene_type_aggregations, compute_scene_type_ade_fde\n",
    "from l5kit.cle.validators import ValidationCountingAggregator\n",
    "from l5kit.dataset import EgoDataset\n",
    "from l5kit.environment.callbacks import L5KitEvalCallback\n",
    "from l5kit.environment.gym_metric_set import CLEMetricSet\n",
    "from l5kit.environment.utils import get_scene_types\n",
    "from l5kit.simulation.dataset import SimulationConfig\n",
    "from l5kit.simulation.unroll import ClosedLoopSimulator\n",
    "from stable_baselines3.common.logger import Logger\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from stable_baselines3.common import utils\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import simulation_out_to_visualizer_scene, episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.data import MapAPI\n",
    "\n",
    "scene_id_to_type_path = '../../dataset_metadata/validate_turns_metadata.csv'\n",
    "\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./drivenet_config.yaml\")\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Validation Dataset\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "mapAPI = MapAPI.from_cfg(dm ,cfg)\n",
    "eval_dataset = EgoDataset(cfg, eval_zarr, rasterizer)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: torch.nn.Module, dataset: EgoDataset, logger: Logger, d_set: str, iter_num: int,\n",
    "               num_scenes_to_unroll: int, num_simulation_steps: int = None,\n",
    "               enable_scene_type_aggregation: Optional[bool] = False,\n",
    "               scene_id_to_type_path: Optional[str] = None) -> None:\n",
    "    \"\"\"Evaluator function for the drivenet model. Evaluate the model using the CLEMetricSet\n",
    "    of L5Kit. Logging is performed in the Tensorboard logger.\n",
    "\n",
    "    :param model: the trained model to evaluate\n",
    "    :param dataset: the dataset on which the models is evaluated\n",
    "    :param logger: tensorboard logger to log the evaluation results\n",
    "    :param d_set: the type of dataset being evaluated (\"train\" or \"eval\")\n",
    "    :param iter_num: iteration number of training (to log in tensorboard)\n",
    "    :param num_scenes_to_unroll: Number of scenes to evaluate in the dataset\n",
    "    :param num_simulation_steps: Number of steps to unroll the model for.\n",
    "    :param enable_scene_type_aggregation: enable evaluation according to scene type\n",
    "    :param scene_id_to_type_path: path to the csv file mapping scene id to scene type\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # Close Loop Simulation\n",
    "    sim_cfg = SimulationConfig(use_ego_gt=False, use_agents_gt=True, disable_new_agents=False,\n",
    "                               distance_th_far=30, distance_th_close=15, num_simulation_steps=num_simulation_steps,\n",
    "                               start_frame_index=0, show_info=False)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sim_loop = ClosedLoopSimulator(sim_cfg, dataset, device, model_ego=model, model_agents=None)\n",
    "\n",
    "    # metric set\n",
    "    metric_set = CLEMetricSet()\n",
    "\n",
    "    # unroll\n",
    "    batch_unroll = 100\n",
    "    for start_idx in range(0, num_scenes_to_unroll, batch_unroll):\n",
    "        end_idx = min(num_scenes_to_unroll, start_idx + batch_unroll)\n",
    "        scenes_to_unroll = list(range(start_idx, end_idx))\n",
    "        sim_outs = sim_loop.unroll(scenes_to_unroll)\n",
    "        metric_set.evaluator.evaluate(sim_outs)\n",
    "\n",
    "    # Aggregate metrics (ADE, FDE)\n",
    "    ade, fde = L5KitEvalCallback.compute_ade_fde(metric_set)\n",
    "    print(f'{d_set}/ade', round(ade, 3))\n",
    "    print(f'{d_set}/fde', round(fde, 3))\n",
    "    \n",
    "    return sim_outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92694b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give model path and make sure config.yaml respects the model\n",
    "# model_path = \"./checkpoints/drivenet_h0_p05_default_schedule_step5_full_757425_steps.pt\"\n",
    "model_path = \"./checkpoints/drivenet_h0_p05_onecycle_schedule_step5_wt_rew_full_757425_steps.pt\"\n",
    "num_scenes_to_unroll = 5\n",
    "\n",
    "model = torch.load(model_path).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "sim_outs = eval_model(model, eval_dataset, None, \"eval\", 2000000, num_scenes_to_unroll, num_simulation_steps=None)\n",
    "print(\"Time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221905a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "for sim_out in sim_outs: # for each scene\n",
    "    vis_in = simulation_out_to_visualizer_scene(sim_out, mapAPI)\n",
    "    show(visualize(sim_out.scene_id, vis_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give model path and make sure config.yaml respects the model\n",
    "model_path = \"./checkpoints/drivenet_h0_p05_default_schedule_step5_full_757425_steps.pt\"\n",
    "# model_path = \"./checkpoints/drivenet_h0_p05_onecycle_schedule_step5_wt_rew_full_757425_steps.pt\"\n",
    "num_scenes_to_unroll = 5\n",
    "\n",
    "model = torch.load(model_path).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "sim_outs = eval_model(model, eval_dataset, None, \"eval\", 2000000, num_scenes_to_unroll, num_simulation_steps=None)\n",
    "print(\"Time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "for sim_out in sim_outs: # for each scene\n",
    "    vis_in = simulation_out_to_visualizer_scene(sim_out, mapAPI)\n",
    "    show(visualize(sim_out.scene_id, vis_in))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
